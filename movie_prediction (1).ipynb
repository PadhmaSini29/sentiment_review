{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9aa717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\lgspa\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lgspa\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lgspa\\anaconda3\\lib\\site-packages (from xgboost) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d580233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/lgspa/Downloads/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0c5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment labels to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890f88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    df['review'], df['sentiment'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ea8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text data into a bag-of-words representation using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_data_vectorized = vectorizer.fit_transform(train_data)\n",
    "test_data_vectorized = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27306fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a classifier\n",
    "def train_and_evaluate_classifier(classifier, train_data, test_data, train_labels, test_labels):\n",
    "    classifier.fit(train_data, train_labels)\n",
    "    predictions = classifier.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    report = classification_report(test_labels, predictions)\n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88f78611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8488\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      4961\n",
      "           1       0.87      0.82      0.85      5039\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_accuracy, nb_report = train_and_evaluate_classifier(nb_classifier, train_data_vectorized, test_data_vectorized, train_labels, test_labels)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "print(\"Naive Bayes Classification Report:\\n\", nb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d569ab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8578\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4961\n",
      "           1       0.86      0.86      0.86      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_accuracy, rf_report = train_and_evaluate_classifier(rf_classifier, train_data_vectorized, test_data_vectorized, train_labels, test_labels)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\\n\", rf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44f9ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lgspa\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.6426\n",
      "KNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61      4961\n",
      "           1       0.63      0.72      0.67      5039\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.65      0.64      0.64     10000\n",
      "weighted avg       0.65      0.64      0.64     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN) Classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_accuracy, knn_report = train_and_evaluate_classifier(knn_classifier, train_data_vectorized, test_data_vectorized, train_labels, test_labels)\n",
    "print(\"KNN Accuracy:\", knn_accuracy)\n",
    "print(\"KNN Classification Report:\\n\", knn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8993e357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8637\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      4961\n",
      "           1       0.85      0.89      0.87      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoosting Classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "xgb_accuracy, xgb_report = train_and_evaluate_classifier(xgb_classifier, train_data_vectorized, test_data_vectorized, train_labels, test_labels)\n",
    "print(\"XGBoost Accuracy:\", xgb_accuracy)\n",
    "print(\"XGBoost Classification Report:\\n\", xgb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f046d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8912\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      4961\n",
      "           1       0.89      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lgspa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_accuracy, lr_report = train_and_evaluate_classifier(lr_classifier, train_data_vectorized, test_data_vectorized, train_labels, test_labels)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Logistic Regression Classification Report:\\n\", lr_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "267b5549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7241\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.72      4961\n",
      "           1       0.73      0.72      0.72      5039\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.72     10000\n",
      "weighted avg       0.72      0.72      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_accuracy, dt_report = train_and_evaluate_classifier(dt_classifier, train_data_vectorized, test_data_vectorized, train_labels, test_labels)\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"Decision Tree Classification Report:\\n\", dt_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ff27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment based on user input\n",
    "def predict_sentiment(review):\n",
    "    review_vectorized = vectorizer.transform([review])\n",
    "    prediction = nb_classifier.predict(review_vectorized)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "debf3d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a movie review: I sure would like to see a resurrection of a up dated Seahunt series with the tech they have today it would bring back the kid excitement in me.I grew up on black and white TV and Seahunt with Gunsmoke were my hero's every week.You have my vote for a comeback of a new sea hunt.We need a change of pace in TV and this would work for a world of under water adventure.Oh by the way thank you for an outlet like this to view many viewpoints about TV and the many movies.So any ole way I believe I've got what I wanna say.Would be nice to read some more plus points about sea hunt.If my rhymes would be 10 lines would you let me submit,or leave me out to be in doubt and have me to quit,If this is so then I must go so lets do it.\n"
     ]
    }
   ],
   "source": [
    "# Ask the user for a movie review\n",
    "user_review = input(\"Enter a movie review: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "568e93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment\n",
    "prediction = predict_sentiment(user_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "368de948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is NEGATIVE.\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "if prediction == 'positive':\n",
    "    print(\"The sentiment is POSITIVE.\")\n",
    "else:\n",
    "    print(\"The sentiment is NEGATIVE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbd4087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate error\n",
    "def calculate_error(predictions, actual_labels):\n",
    "    incorrect_predictions = (predictions != actual_labels).sum()\n",
    "    total_samples = len(actual_labels)\n",
    "    error = incorrect_predictions / total_samples\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d2d262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Error: 0.1088\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for the test data using the Logistic Regression classifier\n",
    "lr_predictions = lr_classifier.predict(test_data_vectorized)\n",
    "\n",
    "# Calculate the error\n",
    "lr_error = calculate_error(lr_predictions, test_labels)\n",
    "print(\"Logistic Regression Error:\", lr_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f437e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
